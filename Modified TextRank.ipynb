{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string\n",
    "from itertools import combinations\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english') + [i for i in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentence Extraction\n",
    "#similarity function\n",
    "def sent_sim(s1, s2):\n",
    "    common = float(sum([word in s2 for word in s1]))\n",
    "    if common == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return common/ (np.log(len(s1)) + np.log(len(s2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normal TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = brown.sents('ca19')\n",
    "G = np.diag([1.0]*len(sentences))\n",
    "tagged_sentences = brown.tagged_sents('ca19')\n",
    "scores = [1.0]*len(sentences)\n",
    "filtered_sentences = [[word[0].lower() for word in sentence \n",
    "                       if word[0] not in stop and word[1] in\n",
    "                       ['NN', 'JJ', 'VB', 'NP', 'NNS', 'RB', 'VBN', 'VBG'] \n",
    "                       and len(word[0]) > 2] for sentence in tagged_sentences]\n",
    "#populate graph\n",
    "for i,j in combinations(range(len(filtered_sentences)), 2):\n",
    "    G[i][j] = sent_sim(filtered_sentences[i], filtered_sentences[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_sentence(G, v, d, scores):\n",
    "    return (1.0 - d) + d*sum([float(scores[i])*G[v][i]/sum(G.T[i]) for i in xrange(len(G[v]))])\n",
    "\n",
    "converged = False\n",
    "while not converged:\n",
    "    converged = True\n",
    "    for node in xrange(len(sentences)):\n",
    "        old_score = scores[node]\n",
    "        scores[node] = score_sentence(G, node, 0.85, scores)\n",
    "        if abs(scores[node] - old_score) > 0.0001:\n",
    "            converged = False\n",
    "            \n",
    "summary_sents = sorted([index for (score, index) in sorted([(scores[i], i) for i in xrange(len(scores))], reverse=True)[:5]])            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baltimore and Ohio Railroad announced yesterday it would reduce the total amount of its payroll by 10 per cent through salary cuts and lay-offs effective at 12:01 A.M. next Saturday .\n",
      "The reduction in expenses will affect employees in the thirteen states in which the B. & O. operates .\n",
      "A thug struck a cab driver in the face with a pistol last night after robbing him of $18 at Franklin and Mount Streets .\n",
      "A baby was burned to death and two other children were seriously injured last night in a fire which damaged their one-room Anne Arundel county home .\n",
      "His sister and brother , Marie Louise , 3 , and John Raymond , Jr. 22 months , were admitted to the hospital .\n"
     ]
    }
   ],
   "source": [
    "for sent in summary_sents:\n",
    "    print ' '.join(sentences[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modified TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = brown.sents('ca19')\n",
    "G = np.diag([1.0]*len(sentences))\n",
    "tagged_sentences = brown.tagged_sents('ca19')\n",
    "scores = [1.0]*len(sentences)\n",
    "summary = []\n",
    "summary_words = set()\n",
    "while len(summary) < 5:\n",
    "    filtered_sentences = [[word[0].lower() for word in sentence \n",
    "                           if word[0] not in stop and word[1] in\n",
    "                           ['NN', 'JJ', 'VB', 'NP', 'NNS', 'RB', 'VBN', 'VBG'] and word[0] not in summary_words\n",
    "                           and len(word[0]) > 2] for sentence in tagged_sentences]\n",
    "    #populate graph\n",
    "    for i,j in combinations(range(len(filtered_sentences)), 2):\n",
    "        G[i][j] = sent_sim(filtered_sentences[i], filtered_sentences[j])\n",
    "        \n",
    "    converged = False\n",
    "    while not converged:\n",
    "        converged = True\n",
    "        for node in xrange(len(sentences)):\n",
    "            old_score = scores[node]\n",
    "            scores[node] = score_sentence(G, node, 0.85, scores)\n",
    "            if abs(scores[node] - old_score) > 0.0001:\n",
    "                converged = False\n",
    "    new_sent = sorted([(scores[i], i) for i in xrange(len(scores))], reverse=True)[0][1]\n",
    "    summary.append(new_sent)\n",
    "    summary_words = summary_words.union(sentences[new_sent])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Baltimore and Ohio Railroad announced yesterday it would reduce the total amount of its payroll by 10 per cent through salary cuts and lay-offs effective at 12:01 A.M. next Saturday .\n",
      "The reduction in expenses will affect employees in the thirteen states in which the B. & O. operates .\n",
      "A thug struck a cab driver in the face with a pistol last night after robbing him of $18 at Franklin and Mount Streets .\n",
      "The driver told police he followed as the Negro man got out of the cab with his money .\n",
      "A baby was burned to death and two other children were seriously injured last night in a fire which damaged their one-room Anne Arundel county home .\n"
     ]
    }
   ],
   "source": [
    "for sent in sorted(summary):\n",
    "    print ' '.join(sentences[sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need more than 1 value to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-d38b91ca74fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dog\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Kevin/anaconda/lib/python2.7/site-packages/nltk/corpus/reader/wordnet.pyc\u001b[0m in \u001b[0;36msynset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msynset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0;31m# split name into lemma, part of speech and synset number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0mlemma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msynset_index_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0msynset_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynset_index_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need more than 1 value to unpack"
     ]
    }
   ],
   "source": [
    "wn.synset(\"dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank(D, k):\n",
    "    from nltk.corpus import stopwords\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
